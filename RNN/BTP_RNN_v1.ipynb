{"cells":[{"cell_type":"code","metadata":{"id":"5o_rheLFNJQH","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","\n","calls_train = pd.read_csv('/gdrive/My Drive/btp/378calls_data.csv')\n","users = pd.Categorical(calls_train.user.unique())\n","users_new = users.codes\n","new_ids = pd.DataFrame({'user':users.categories,'user_id':users_new})\n","calls_train = pd.merge(calls_train, new_ids, on='user')\n","del calls_train['user']\n","#calls_train = calls_train[['user_id', 'duration','month', 'date', 'hour', 'minute', 'second']]\n","calls_train = calls_train[['user_id', 'duration', 'time_normalized']]\n","calls_train = calls_train.sort_values(by=['time_normalized'])\n","calls_train = calls_train.reset_index()\n","del calls_train['index']\n","cols = pd.get_dummies(calls_train.user_id).columns\n","calls_train[cols] = pd.get_dummies(calls_train.user_id)\n","columnss = ['user_id']+cols.to_list()\n","# columnss+=['duration','month', 'date', 'hour', 'minute', 'second']\n","columnss+=['duration', 'time_normalized']\n","calls_train = calls_train[columnss]\n","#adding noise to duration column\n","# calls_train['a'] = np.random.normal(0,0.4, calls_train.shape[0])\n","# calls_train['b'] = np.random.normal(1,2, calls_train.shape[0])\n","# calls_train['c'] = np.random.normal(2,0.6, calls_train.shape[0])\n","# calls_train['d'] = np.random.normal(3,0.9, calls_train.shape[0])\n","# calls_train['e'] = np.random.normal(4,3, calls_train.shape[0])\n","# calls_train['f'] = np.random.normal(5,1, calls_train.shape[0])\n","# calls_train['a']/=calls_train['a'].max()\n","# calls_train['b']/=calls_train['b'].max()\n","# calls_train['c']/=calls_train['c'].max()\n","# calls_train['d']/=calls_train['d'].max()\n","# calls_train['e']/=calls_train['e'].max()\n","# calls_train['f']/=calls_train['f'].max()\n","#noise = np.random.normal(0, 1, calls_train.shape[0])\n","#calls_train.duration = calls_train.duration*noise\n","# calls_train.duration/=calls_train.duration.max()\n","# calls_train.month/=calls_train.month.max()\n","# calls_train.date/=calls_train.date.max()\n","# calls_train.hour/=calls_train.hour.max()\n","# calls_train.minute/=calls_train.minute.max()\n","# calls_train.second/=calls_train.second.max()\n","calls_train.to_csv('/content/large_calls_data.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TeNS3j-jKE1z","colab_type":"code","outputId":"399bd66c-7670-4f9e-a437-55d9c29e1e64","executionInfo":{"status":"ok","timestamp":1590677478666,"user_tz":-330,"elapsed":4161,"user":{"displayName":"manoj koneni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeLlu20cBA46bY94vGaZWUdmNsxzAgjsZC6YFB5A=s64","userId":"04353693995651475995"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","import pandas as pd\n","import pickle as pkl\n","import logging\n","\n","dev = torch.device(\n","    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","# dev = torch.device(\"cpu\")\n","print(dev)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tG7-uNS6KO1X","colab_type":"code","outputId":"1aa8d75f-651e-41cf-9eed-5cba845c9a79","executionInfo":{"status":"ok","timestamp":1590677487940,"user_tz":-330,"elapsed":4271,"user":{"displayName":"manoj koneni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeLlu20cBA46bY94vGaZWUdmNsxzAgjsZC6YFB5A=s64","userId":"04353693995651475995"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data = pd.read_csv(\"./large_calls_data.csv\")\n","del data['user_id']\n","# del data['time_normalized']\n","# train_data = data[0:123000]\n","# test_data = data[123000:]\n","train_data = data[:81000]\n","test_data = data[81000:]\n","train_data = torch.tensor(train_data.values)\n","#d = d.index_select(1,torch.LongTensor([x for x in range(28)]))\n","test_data = torch.tensor(test_data.values)\n","print(\"train_dataset:\",train_data.shape, \" test_dataset:\",test_data.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KQEjOMmqKh0A","colab_type":"code","colab":{}},"source":["class RNN_v1(nn.Module):\n","    def __init__(self, batch_size, n_steps, input_size, output_size, hidden_size, softmax):\n","        super(RNN_v1, self).__init__()\n","        self.bs = batch_size\n","        self.n_steps = n_steps\n","        self.h_neurons = hidden_size\n","        self.input_size = input_size\n","        self.output_size = output_size\n","        # self.rnn = nn.RNN(input_size = self.input_size, hidden_size = self.h_neurons, num_layers = 1, batch_first=True, \n","        #                   nonlinearity = 'tanh', dropout = 0, bias = True)\n","        self.rnn = nn.LSTM(input_size = self.input_size, hidden_size = self.h_neurons, num_layers = 1, batch_first=True,dropout= 0, bias = True)\n","        self.final_layer = nn.Linear(self.h_neurons, 380)   ##378 users+ duration + time normalized column\n","        torch.nn.init.xavier_uniform_(self.final_layer.weight)\n","        self.softmax = softmax\n","        \n","    def forward(self, X):\n","        #h0 = torch.zeros(1, self.bs, self.h_neurons).to(dev)\n","        X, _ = self.rnn(X)\n","        X = self.final_layer(X)\n","        f = torch.zeros(1,380)\n","        for i in range(self.bs):\n","            if i==0:\n","                f = X[i][-1].view(1,-1)\n","            else:\n","                f = torch.cat((f, X[i][-1].view(1,-1)), dim=0)\n","        return f"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dmd9gaoBKlkQ","colab_type":"code","colab":{}},"source":["loss = nn.CrossEntropyLoss()\n","mseLoss = nn.MSELoss()\n","l1loss = nn.L1Loss(reduction='mean')\n","z = [x for x in range(378)]\n","\n","def loss_func(X,Y):\n","    ce_loss = loss(X.cpu().index_select(1, torch.LongTensor(z)), np.argmax(Y.cpu().index_select(1, torch.LongTensor(z)), axis=1))\n","    #print('2',X.shape, Y.shape)\n","    duration_loss = l1loss(Y.cpu().index_select(1, torch.LongTensor([378, 379])).float(),X.cpu().index_select(1, torch.LongTensor([378,379])))\n","    # for i in range(6):\n","    #   added_feature_loss += mseLoss(Y.cpu().index_select(1, torch.LongTensor([754+i])).float(),X.cpu().index_select(1, torch.LongTensor([754+i])))\n","    total_loss = ce_loss+duration_loss\n","    return total_loss.to(dev)\n","    \n","train_data = torch.tensor(data[0:72000].values)\n","validation_data = torch.tensor(data[72000:].values)\n","\n","    \n","def preproc_input(bs, k, dataset):\n","    i = 0\n","    if dataset == 'train':\n","        y = train_data[k+1:k+bs+1]\n","    elif dataset == 'valid':\n","        y = validation_data[k+1:k+bs+1]\n","    elif dataset == 'test':\n","        y = test_data[k+1:k+bs+1]\n","    x = torch.zeros(1,10,380)\n","    #print('reached here')\n","    while i< bs:\n","        if i==0:\n","            if dataset == 'train':\n","                x = train_data[i+k:(i+k+10)].view(1,10,-1)\n","            elif dataset == 'valid':\n","                x = validation_data[i+k:(i+k+10)].view(1,10,-1)\n","            elif dataset == 'test':\n","                x = test_data[i+k:(i+k+10)].view(1,10,-1)\n","        else:\n","            if dataset == 'train':\n","                x = torch.cat((x, train_data[i+k:(i+k+10)].view(1,10,-1)), dim=0)\n","            elif dataset == 'valid':\n","                x = torch.cat((x, validation_data[i+k:(i+k+10)].view(1,10,-1)), dim=0)\n","            elif dataset == 'test':\n","                x = torch.cat((x, test_data[i+k:(i+k+10)].view(1,10,-1)), dim=0)\n","        i+=1\n","        #print('error')\n","        #print(\"dataset: \",dataset, i+k, i+k+10, \" i \",i, \" k \",k)\n","    return x.to(dev),y.to(dev)\n","    \n","def calc_accuracy(x, y):\n","    predicted = np.argmax(x.detach().cpu().index_select(1, torch.LongTensor(z)), axis=1)\n","    true_labels = np.argmax(y.cpu().index_select(1, torch.LongTensor(z)), axis=1)\n","    #print(predicted, true_labels)\n","    accuracy = torch.sum(torch.eq(predicted, true_labels))/predicted.shape[0]\n","    return accuracy.item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZTC_JhkzKqCb","colab_type":"code","colab":{}},"source":["def train(epochs, optimizer, rnn, train_data, bs):\n","    for epoch in range(epochs):\n","        ind, train_loss, train_accuracy=0, 0, 0\n","        rnn.train()\n","        while ind<=(train_data.shape[0]-2*bs):\n","            x, y = preproc_input(bs, ind, 'train')\n","            #print('done1')\n","            ind+=20\n","            optimizer.zero_grad()\n","            y_pred = rnn(x.float())\n","            #print('done2')\n","            #print(ind<=(train_data.shape[0]-2*bs))\n","            t_loss = loss_func(y_pred, y)\n","            #print('done3')\n","            t_loss.backward()\n","            optimizer.step()\n","            #print('done4')\n","            train_loss+=t_loss.item()\n","            train_accuracy+= calc_accuracy(y_pred, y)\n","            #print('done5')\n","        train_loss/=(ind/20)\n","        train_accuracy/=(ind/20)\n","        #########------------------validation----------------------##########\n","        print(\"in validation\")\n","        rnn.eval()\n","        with torch.no_grad():\n","            v_ind,valid_accuracy, valid_loss = 0,0,0\n","            while(v_ind<= validation_data.shape[0]-2*bs):\n","                x,y = preproc_input(bs, v_ind, 'valid')\n","                v_ind+=20\n","                v_pred = rnn(x.float())\n","                v_loss = loss_func(v_pred, y)\n","                valid_loss+=v_loss.item()\n","                valid_accuracy+= calc_accuracy(v_pred,y)\n","            valid_loss/=(v_ind/20)\n","            valid_accuracy/=(v_ind/20)\n","        print(\"epoch: \", epoch, \" train_loss:\", train_loss, \" train_accuracy:\", train_accuracy, \" validation_loss:\", valid_loss,\n","             \" validation_accuracy: \", valid_accuracy)\n","        logging.info(\"%d,      %f,    %f,       %f,         %f\", epoch, train_loss, train_accuracy, valid_loss, valid_accuracy)\n","        if(epoch%10==0):\n","            torch.save(rnn,\"lstm_new\"+str(epoch)+\".pkl\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cf6wRmdSKuDw","colab_type":"code","outputId":"fbef119f-ebe3-45e7-a1ea-3bf6cdad66a2","executionInfo":{"status":"ok","timestamp":1590682793523,"user_tz":-330,"elapsed":5205586,"user":{"displayName":"manoj koneni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeLlu20cBA46bY94vGaZWUdmNsxzAgjsZC6YFB5A=s64","userId":"04353693995651475995"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["rnn = RNN_v1(20, 10, 380, 380, 128, F.softmax)\n","rnn.to(dev)\n","\n","optimizer = optim.Adam(rnn.parameters(), lr=1e-3)\n","\n","logging.basicConfig(filename='/content/rnnLog_new.txt', filemode='w', format='%(asctime)s - %(message)s',level=logging.INFO)\n","logging.info(\"parms: lr=1e-3, batch size=20 ,session length=10, hidden layers=1, hidden size=128\")\n","logging.info(\"epoch, train_loss, train_accuracy, validation_loss, validation_accuracy\")\n","\n","train(101, optimizer, rnn, train_data, 20)\n","#for epoch in range(6):\n","#    test_model = torch.load('./csv/rnn'+str(epoch*10)+'.pkl')\n","#    test(test_model, test_data, 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EaqsznPxKyZd","colab_type":"code","colab":{}},"source":["#generate data\n","\n","rnn = torch.load('/content/lstm_new100.pkl')\n","predictions = []\n","true_values = []\n","def test(rnn, test_data, bs):\n","    rnn.eval()\n","    with torch.no_grad():\n","        v_ind,test_loss, test_accuracy = 0,0,0\n","        while(v_ind<= test_data.shape[0]-2*bs):\n","            x,y = preproc_input(bs, v_ind, 'test')\n","            v_ind+=20\n","            v_pred = rnn(x.float())\n","            predictions.append(v_pred)\n","            true_values.append(y)\n","            v_loss = loss_func(v_pred, y)\n","            test_loss+=v_loss.item()\n","            test_accuracy+= calc_accuracy(v_pred,y)\n","        test_loss/=(v_ind/20)\n","        test_accuracy/=(v_ind/20)\n","        print( \"test_loss:\", test_loss, \" test_accuracy:\", test_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MViuntr3y5O-","colab_type":"code","outputId":"e3f6b849-c518-498a-8338-53d31269f36d","executionInfo":{"status":"ok","timestamp":1590683545462,"user_tz":-330,"elapsed":7475,"user":{"displayName":"manoj koneni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeLlu20cBA46bY94vGaZWUdmNsxzAgjsZC6YFB5A=s64","userId":"04353693995651475995"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test(rnn, test_data, 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f1DpKBjA1S9A","colab_type":"code","outputId":"5599abd6-f6fe-43d1-8f12-88b36ffc73ab","executionInfo":{"status":"ok","timestamp":1590683567202,"user_tz":-330,"elapsed":15930,"user":{"displayName":"manoj koneni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeLlu20cBA46bY94vGaZWUdmNsxzAgjsZC6YFB5A=s64","userId":"04353693995651475995"}},"colab":{"base_uri":"https://localhost:8080/","height":373}},"source":["a = np.append(predictions[0].cpu().numpy(), predictions[1].cpu().numpy(), axis=0)\n","b = np.append(true_values[0].cpu().numpy(), true_values[1].cpu().numpy(), axis=0)\n","for i in range(2,len(predictions)):\n","  a = np.append(a, predictions[i].cpu().numpy(), axis=0)\n","  b = np.append(b, true_values[i].cpu().numpy(), axis=0)\n","  preds = pd.DataFrame(a)\n","preds.names = [z for z in range(380)]\n","preds['duration'] = preds[378]\n","preds['time_normalized'] = preds[379]\n","del preds[378]\n","del preds[379]\n","print(preds.head())\n","tru = pd.DataFrame(b)\n","tru.names = [z for z in range(380)]\n","tru['duration'] = tru[378]\n","tru['time_normalized'] = tru[379]\n","del tru[378]\n","del tru[379]\n","print(tru.head())\n","c = [z for z in range(378)]\n","preds['user_id'] = preds[z].idxmax(axis=1)\n","tru['user_id'] = tru[z].idxmax(axis=1)\n","pred1 = preds[['user_id', 'duration', 'time_normalized']]\n","tru1 = tru[['user_id', 'duration', 'time_normalized']]\n","pred1.to_csv('/content/lstm_prediction_100.csv', index=False)\n","#tru1.to_csv('/content/lstm_true_labels.csv', index=False)"],"execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"BTP_RNN_v1.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPmDeaxjUlbuZ4Z902hFhC5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}