{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This code runs on synthetically generated data from \"../data_preprocessing/Synthetic data generation and preprocessing.ipynb\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The below cell converts user part into one hot encoding vector, sort the data by time stamp and saves it in new data file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5o_rheLFNJQH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "calls_train = pd.read_csv('../data/378calls_data.csv')\n",
    "users = pd.Categorical(calls_train.user.unique())\n",
    "users_new = users.codes\n",
    "new_ids = pd.DataFrame({'user':users.categories,'user_id':users_new})\n",
    "calls_train = pd.merge(calls_train, new_ids, on='user')\n",
    "del calls_train['user']\n",
    "#calls_train = calls_train[['user_id', 'duration','month', 'date', 'hour', 'minute', 'second']]\n",
    "calls_train = calls_train[['user_id', 'duration', 'time_normalized']]\n",
    "calls_train = calls_train.sort_values(by=['time_normalized'])\n",
    "calls_train = calls_train.reset_index()\n",
    "del calls_train['index']\n",
    "cols = pd.get_dummies(calls_train.user_id).columns\n",
    "calls_train[cols] = pd.get_dummies(calls_train.user_id)\n",
    "columnss = ['user_id']+cols.to_list()\n",
    "# columnss+=['duration','month', 'date', 'hour', 'minute', 'second']\n",
    "columnss+=['duration', 'time_normalized']\n",
    "calls_train = calls_train[columnss]\n",
    "calls_train.to_csv('../data/large_calls_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4161,
     "status": "ok",
     "timestamp": 1590677478666,
     "user": {
      "displayName": "manoj koneni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeLlu20cBA46bY94vGaZWUdmNsxzAgjsZC6YFB5A=s64",
      "userId": "04353693995651475995"
     },
     "user_tz": -330
    },
    "id": "TeNS3j-jKE1z",
    "outputId": "399bd66c-7670-4f9e-a437-55d9c29e1e64"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import logging\n",
    "\n",
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# dev = torch.device(\"cpu\")\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Train test split(70:30)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4271,
     "status": "ok",
     "timestamp": 1590677487940,
     "user": {
      "displayName": "manoj koneni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeLlu20cBA46bY94vGaZWUdmNsxzAgjsZC6YFB5A=s64",
      "userId": "04353693995651475995"
     },
     "user_tz": -330
    },
    "id": "tG7-uNS6KO1X",
    "outputId": "1aa8d75f-651e-41cf-9eed-5cba845c9a79"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/large_calls_data.csv\")\n",
    "del data['user_id']\n",
    "train_data = data[:81000]\n",
    "test_data = data[81000:]\n",
    "train_data = torch.tensor(train_data.values)\n",
    "#d = d.index_select(1,torch.LongTensor([x for x in range(28)]))\n",
    "test_data = torch.tensor(test_data.values)\n",
    "print(\"train_dataset:\",train_data.shape, \" test_dataset:\",test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*resource predictor model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQEjOMmqKh0A"
   },
   "outputs": [],
   "source": [
    "class RNN_v1(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, input_size, output_size, hidden_size, softmax):\n",
    "        super(RNN_v1, self).__init__()\n",
    "        self.bs = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.h_neurons = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.rnn = nn.RNN(input_size = self.input_size, hidden_size = self.h_neurons, num_layers = 1, batch_first=True, \n",
    "                           nonlinearity = 'tanh', dropout = 0, bias = True)\n",
    "        #self.rnn = nn.LSTM(input_size = self.input_size, hidden_size = self.h_neurons, num_layers = 1, batch_first=True,dropout= 0, bias = True)\n",
    "        self.final_layer = nn.Linear(self.h_neurons, 380)   ##378 users+ duration + time normalized column\n",
    "        torch.nn.init.xavier_uniform_(self.final_layer.weight)\n",
    "        self.softmax = softmax\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X, _ = self.rnn(X)\n",
    "        X = self.final_layer(X)\n",
    "        f = torch.zeros(1,380)\n",
    "        for i in range(self.bs):\n",
    "            if i==0:\n",
    "                f = X[i][-1].view(1,-1)\n",
    "            else:\n",
    "                f = torch.cat((f, X[i][-1].view(1,-1)), dim=0)\n",
    "        return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The below cell is for loss calculation,converting the input into required batch-size for MLP input and calculating train, validation and test accuracies.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dmd9gaoBKlkQ"
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "mseLoss = nn.MSELoss()\n",
    "l1loss = nn.L1Loss(reduction='mean')\n",
    "z = [x for x in range(378)]\n",
    "\n",
    "def loss_func(X,Y):\n",
    "    ce_loss = loss(X.cpu().index_select(1, torch.LongTensor(z)), np.argmax(Y.cpu().index_select(1, torch.LongTensor(z)), axis=1))\n",
    "    duration_loss = l1loss(Y.cpu().index_select(1, torch.LongTensor([378, 379])).float(),X.cpu().index_select(1, torch.LongTensor([378,379])))\n",
    "    total_loss = ce_loss+duration_loss\n",
    "    return total_loss.to(dev)\n",
    "    \n",
    "train_data = torch.tensor(data[0:72000].values)\n",
    "validation_data = torch.tensor(data[72000:].values)\n",
    "\n",
    "    \n",
    "def preproc_input(bs, k, dataset):\n",
    "    i = 0\n",
    "    if dataset == 'train':\n",
    "        y = train_data[k+1:k+bs+1]\n",
    "    elif dataset == 'valid':\n",
    "        y = validation_data[k+1:k+bs+1]\n",
    "    elif dataset == 'test':\n",
    "        y = test_data[k+1:k+bs+1]\n",
    "    x = torch.zeros(1,10,380)\n",
    "    while i< bs:\n",
    "        if i==0:\n",
    "            if dataset == 'train':\n",
    "                x = train_data[i+k:(i+k+10)].view(1,10,-1)\n",
    "            elif dataset == 'valid':\n",
    "                x = validation_data[i+k:(i+k+10)].view(1,10,-1)\n",
    "            elif dataset == 'test':\n",
    "                x = test_data[i+k:(i+k+10)].view(1,10,-1)\n",
    "        else:\n",
    "            if dataset == 'train':\n",
    "                x = torch.cat((x, train_data[i+k:(i+k+10)].view(1,10,-1)), dim=0)\n",
    "            elif dataset == 'valid':\n",
    "                x = torch.cat((x, validation_data[i+k:(i+k+10)].view(1,10,-1)), dim=0)\n",
    "            elif dataset == 'test':\n",
    "                x = torch.cat((x, test_data[i+k:(i+k+10)].view(1,10,-1)), dim=0)\n",
    "        i+=1\n",
    "        #print('error')\n",
    "        #print(\"dataset: \",dataset, i+k, i+k+10, \" i \",i, \" k \",k)\n",
    "    return x.to(dev),y.to(dev)\n",
    "    \n",
    "def calc_accuracy(x, y):\n",
    "    predicted = np.argmax(x.detach().cpu().index_select(1, torch.LongTensor(z)), axis=1)\n",
    "    true_labels = np.argmax(y.cpu().index_select(1, torch.LongTensor(z)), axis=1)\n",
    "    #print(predicted, true_labels)\n",
    "    accuracy = torch.sum(torch.eq(predicted, true_labels))/predicted.shape[0]\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Training code*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTC_JhkzKqCb"
   },
   "outputs": [],
   "source": [
    "def train(epochs, optimizer, rnn, train_data, bs):\n",
    "    for epoch in range(epochs):\n",
    "        ind, train_loss, train_accuracy=0, 0, 0\n",
    "        rnn.train()\n",
    "        while ind<=(train_data.shape[0]-2*bs):\n",
    "            x, y = preproc_input(bs, ind, 'train')\n",
    "            ind+=20\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = rnn(x.float())\n",
    "            t_loss = loss_func(y_pred, y)\n",
    "            t_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss+=t_loss.item()\n",
    "            train_accuracy+= calc_accuracy(y_pred, y)\n",
    "        train_loss/=(ind/20)\n",
    "        train_accuracy/=(ind/20)\n",
    "        \n",
    "        #########------------------validation----------------------##########\n",
    "        \n",
    "        print(\"in validation\")\n",
    "        rnn.eval()\n",
    "        with torch.no_grad():\n",
    "            v_ind,valid_accuracy, valid_loss = 0,0,0\n",
    "            while(v_ind<= validation_data.shape[0]-2*bs):\n",
    "                x,y = preproc_input(bs, v_ind, 'valid')\n",
    "                v_ind+=20\n",
    "                v_pred = rnn(x.float())\n",
    "                v_loss = loss_func(v_pred, y)\n",
    "                valid_loss+=v_loss.item()\n",
    "                valid_accuracy+= calc_accuracy(v_pred,y)\n",
    "            valid_loss/=(v_ind/20)\n",
    "            valid_accuracy/=(v_ind/20)\n",
    "        print(\"epoch: \", epoch, \" train_loss:\", train_loss, \" train_accuracy:\", train_accuracy, \" validation_loss:\", valid_loss,\n",
    "             \" validation_accuracy: \", valid_accuracy)\n",
    "        logging.info(\"%d,      %f,    %f,       %f,         %f\", epoch, train_loss, train_accuracy, valid_loss, valid_accuracy)\n",
    "        if(epoch%10==0):\n",
    "            torch.save(rnn,\"rnn\"+str(epoch)+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This below cell creates a RNN model and trains it on train dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5205586,
     "status": "ok",
     "timestamp": 1590682793523,
     "user": {
      "displayName": "manoj koneni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeLlu20cBA46bY94vGaZWUdmNsxzAgjsZC6YFB5A=s64",
      "userId": "04353693995651475995"
     },
     "user_tz": -330
    },
    "id": "Cf6wRmdSKuDw",
    "outputId": "fbef119f-ebe3-45e7-a1ea-3bf6cdad66a2"
   },
   "outputs": [],
   "source": [
    "rnn = RNN_v1(20, 10, 380, 380, 128, F.softmax)\n",
    "rnn.to(dev)\n",
    "\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=1e-3)\n",
    "\n",
    "logging.basicConfig(filename='./rnnLog_new.txt', filemode='w', format='%(asctime)s - %(message)s',level=logging.INFO)\n",
    "logging.info(\"parms: lr=1e-3, batch size=20 ,session length=10, hidden layers=1, hidden size=128\")\n",
    "logging.info(\"epoch, train_loss, train_accuracy, validation_loss, validation_accuracy\")\n",
    "\n",
    "train(101, optimizer, rnn, train_data, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The below cell generates predictions using the last saved model during RNN training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EaqsznPxKyZd"
   },
   "outputs": [],
   "source": [
    "#generate data\n",
    "\n",
    "rnn = torch.load('./rnn100.pkl')\n",
    "predictions = []\n",
    "true_values = []\n",
    "def test(rnn, test_data, bs):\n",
    "    rnn.eval()\n",
    "    with torch.no_grad():\n",
    "        v_ind,test_loss, test_accuracy = 0,0,0\n",
    "        while(v_ind<= test_data.shape[0]-2*bs):\n",
    "            x,y = preproc_input(bs, v_ind, 'test')\n",
    "            v_ind+=20\n",
    "            v_pred = rnn(x.float())\n",
    "            predictions.append(v_pred)\n",
    "            true_values.append(y)\n",
    "            v_loss = loss_func(v_pred, y)\n",
    "            test_loss+=v_loss.item()\n",
    "            test_accuracy+= calc_accuracy(v_pred,y)\n",
    "        test_loss/=(v_ind/20)\n",
    "        test_accuracy/=(v_ind/20)\n",
    "        print( \"test_loss:\", test_loss, \" test_accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7475,
     "status": "ok",
     "timestamp": 1590683545462,
     "user": {
      "displayName": "manoj koneni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeLlu20cBA46bY94vGaZWUdmNsxzAgjsZC6YFB5A=s64",
      "userId": "04353693995651475995"
     },
     "user_tz": -330
    },
    "id": "MViuntr3y5O-",
    "outputId": "e3f6b849-c518-498a-8338-53d31269f36d"
   },
   "outputs": [],
   "source": [
    "test(rnn, test_data, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Th below code saves the RNN predictions in ../data/results/ folder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15930,
     "status": "ok",
     "timestamp": 1590683567202,
     "user": {
      "displayName": "manoj koneni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeLlu20cBA46bY94vGaZWUdmNsxzAgjsZC6YFB5A=s64",
      "userId": "04353693995651475995"
     },
     "user_tz": -330
    },
    "id": "f1DpKBjA1S9A",
    "outputId": "5599abd6-f6fe-43d1-8f12-88b36ffc73ab"
   },
   "outputs": [],
   "source": [
    "a = np.append(predictions[0].cpu().numpy(), predictions[1].cpu().numpy(), axis=0)\n",
    "b = np.append(true_values[0].cpu().numpy(), true_values[1].cpu().numpy(), axis=0)\n",
    "for i in range(2,len(predictions)):\n",
    "  a = np.append(a, predictions[i].cpu().numpy(), axis=0)\n",
    "  b = np.append(b, true_values[i].cpu().numpy(), axis=0)\n",
    "  preds = pd.DataFrame(a)\n",
    "preds.names = [z for z in range(380)]\n",
    "preds['duration'] = preds[378]\n",
    "preds['time_normalized'] = preds[379]\n",
    "del preds[378]\n",
    "del preds[379]\n",
    "print(preds.head())\n",
    "tru = pd.DataFrame(b)\n",
    "tru.names = [z for z in range(380)]\n",
    "tru['duration'] = tru[378]\n",
    "tru['time_normalized'] = tru[379]\n",
    "del tru[378]\n",
    "del tru[379]\n",
    "print(tru.head())\n",
    "c = [z for z in range(378)]\n",
    "preds['user_id'] = preds[z].idxmax(axis=1)\n",
    "tru['user_id'] = tru[z].idxmax(axis=1)\n",
    "pred1 = preds[['user_id', 'duration', 'time_normalized']]\n",
    "tru1 = tru[['user_id', 'duration', 'time_normalized']]\n",
    "pred1.to_csv('../data/results/rnn_prediction_100.csv', index=False)\n",
    "#tru1.to_csv('/content/lstm_true_labels.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPmDeaxjUlbuZ4Z902hFhC5",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BTP_RNN_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
